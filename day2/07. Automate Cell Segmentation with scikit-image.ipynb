{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2333250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tifffile numpy matplotlib scikit-image scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bfd8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import gaussian\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import remove_small_objects, binary_closing, disk\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.color import label2rgb\n",
    "from skimage.exposure import equalize_adapthist\n",
    "from skimage.segmentation import watershed\n",
    "from scipy import ndimage as ndi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801ca902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import owncloud\n",
    "import os\n",
    "\n",
    "if not os.path.exists('data'):\n",
    "    print('Creating directory for data')\n",
    "    os.mkdir('data')\n",
    "\n",
    "if not os.path.exists('data/demoMovie.tif'):\n",
    "    oc = owncloud.Client.from_public_link('https://uni-bonn.sciebo.de/s/NwtdrIg5wGdeGcB')\n",
    "    oc.get_file('/', 'data/demoMovie.tif');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875338db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tifffile.imread('data/demoMovie.tif')\n",
    "movie = (data - data.min(axis=(1, 2), keepdims=True)) / (np.ptp(data, axis=(1,2), keepdims=True))\n",
    "movie.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770f2d1e",
   "metadata": {},
   "source": [
    "## Automated ROI Detection  \n",
    "  \n",
    "This module introduces a structured approach for identifying neurons automatically in calcium imaging datasets. Manual annotation is useful for small-scale analysis, but for large experiments, automated Region of Interest (ROI) detection is essential. The process will be divided into four stages â€” enhancing the image, intuition of candidate regions, refining masks, and evaluating results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3569abf6",
   "metadata": {},
   "source": [
    "## **Preprocessing**  \n",
    "  \n",
    "Raw calcium imaging data often contains noise that can obscure the structure of neurons. Before beginning the detection process, it is important to enhance the image so that relevant features are easier to identify. In this section, you will generate projection images from the full movie and apply Gaussian filtering to reduce high-frequency noise.\n",
    "\n",
    "| **Code**                  | **Description**                                                                       |\n",
    "| :------------------------ | :------------------------------------------------------------------------------------ |\n",
    "| `np.mean(movie, axis=0)`  | Compute the **mean** of `movie` across all frames (axis 0 corresponds to frames).     |\n",
    "| `gaussian(proj, sigma=1)` | Apply a **Gaussian filter** to `proj` with a **sigma** value of 1 to smooth the data. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18ebf9f",
   "metadata": {},
   "source": [
    "*How do I smooth images to make it easier for automatic segmentation?*\n",
    "\n",
    "**Example** Use gaussian smoothing with sigma=1 on mean projection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09badc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = np.mean(movie, axis=0)\n",
    "proj_smooth = gaussian(proj, sigma=1)\n",
    "plt.imshow(proj_smooth, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361f1418",
   "metadata": {},
   "source": [
    "Use gaussian smoothing with sigma=10 on mean projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fd85ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90ddba2c",
   "metadata": {},
   "source": [
    "Use gaussian smoothing with sigma=0.5 on mean projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ccd12e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "292f4938",
   "metadata": {},
   "source": [
    "*How can I compare the original with the enhanced to make sure details are not smoothed out?*\n",
    "\n",
    "**Example** Compare mean projection with smoothed (sigma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396818d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = np.mean(movie, axis=0)\n",
    "proj_smooth = gaussian(proj, sigma=0.5)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(proj, cmap='gray')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(proj_smooth, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627ac3be",
   "metadata": {},
   "source": [
    "Compare max projection with smoothed (sigma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8cc6af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc9b9582",
   "metadata": {},
   "source": [
    "Compare standard deviation projection with smoothed (sigma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62796e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4eb32878",
   "metadata": {},
   "source": [
    "## Segmenting Neurons  \n",
    "\n",
    "In this section, you will define ROI boundaries by applying image segmentation techniques. This includes thresholding the smoothed image, applying morphological operations to clean and close the binary mask.\n",
    "\n",
    "| **Code**                                          | **Description**                                                                                           |\n",
    "| :------------------------------------------------ | :-------------------------------------------------------------------------------------------------------- |\n",
    "| `image > np.percentile(image, 1)`                 | Create a **binary mask** where pixel values are greater than the 1st percentile of the image.             |\n",
    "| `plt.contour(binary_mask, colors='red')`          | Plot the **contour** of the **binary mask** in red.                                                       |\n",
    "| `remove_small_objects(binary_mask, min_size=2)`   | **Remove small objects** from the binary mask that are smaller than 2 pixels.                             |\n",
    "| `binary_closing(cleaned_mask, footprint=disk(3))` | Apply **binary closing** to the `cleaned_mask` with a disk-shaped footprint of size 3 to fill small gaps. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a110f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = np.std(movie, axis=0)\n",
    "proj_smooth = gaussian(proj, sigma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6167061",
   "metadata": {},
   "source": [
    "*How do I make a automatically detect neurons in my image?*\n",
    "\n",
    "**Example** Highlight image areas above 1 percentile of smoothed projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82340447",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = proj_smooth.copy()\n",
    "binary_mask = image > np.percentile(image, 1)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.contour(binary_mask, colors='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835f22f2",
   "metadata": {},
   "source": [
    "Highlight image areas above 50 percentile of smoothed projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c35a284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8115c42",
   "metadata": {},
   "source": [
    "Highlight image areas above 90 percentile of smoothed projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57dc9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6da544d1",
   "metadata": {},
   "source": [
    "*How do I make sure that I am not including small, bright pixels that are probably not neurons?*\n",
    "\n",
    "**Example** Clean mask by removing any identified objects smaller than 2px."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672750d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_mask = remove_small_objects(binary_mask, min_size=2)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.contour(cleaned_mask, colors='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0350d7",
   "metadata": {},
   "source": [
    "Clean mask by removing any identified objects smaller than 50px."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8b041e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58dadabc",
   "metadata": {},
   "source": [
    "Clean mask by removing any identified objects smaller than 5px."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d53d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8939300",
   "metadata": {},
   "source": [
    "*How do I close the small gaps in between the detected neuron masks?*\n",
    "\n",
    "**Example** Apply morphological closing using a disk of radius 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3bbeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_mask = binary_closing(cleaned_mask, footprint=disk(3))\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.contour(closed_mask, colors='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1419b7d1",
   "metadata": {},
   "source": [
    "Apply morphological closing using a disk of radius 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584661a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f61d3045",
   "metadata": {},
   "source": [
    "Apply morphological closing using a disk of radius 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc28cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5728ef5",
   "metadata": {},
   "source": [
    "## Identifying ROIs that need Splitting\n",
    "\n",
    "Some of the ROIs may encompass more than one neuron. As imaging resolution and signal complexity increase, it becomes more common for automated methods to group nearby neurons into a single ROI. \n",
    "\n",
    "| **Code**                                            | **Description**                                                                                                      |\n",
    "| :-------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------- |\n",
    "| `labeled_rois == 16`                                | Create a **binary mask** where the **labeled ROIs** are equal to 16.                                                 |\n",
    "| `proj * roi`                                        | Multiply the **projection** (`proj`) by the **ROI mask** (`roi`) to apply the region of interest (ROI) to the image. |\n",
    "| `peak_local_max(roi_crop, min_distance=5)`          | Detect **local peaks** in the cropped ROI (`roi_crop`) with a minimum distance of 5 pixels between peaks.            |\n",
    "| `equalize_adapthist(roi_crop_norm, clip_limit=0.4)` | Apply **adaptive histogram equalization** to normalize the contrast in `roi_crop_norm` with a clip limit of 0.4.     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0842e785",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_rois = label(closed_mask)\n",
    "np.unique(labeled_rois)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f67fcde",
   "metadata": {},
   "source": [
    "*How do I examine the shape of individual neurons?*\n",
    "\n",
    "**Example** Show 16th roi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ff7ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = labeled_rois == 16\n",
    "plt.imshow(roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c0613d",
   "metadata": {},
   "source": [
    "Show 12th roi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5ec3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68009842",
   "metadata": {},
   "source": [
    "Show 11th roi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba145d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "230e0019",
   "metadata": {},
   "source": [
    "*How do I know if there are more intensity blobs inside an ROI?*\n",
    "\n",
    "**Example** Detect local peaks in ROI number 16 using a minimum distance of 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7926bcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = labeled_rois == 16\n",
    "roi_crop = proj * roi\n",
    "coords = peak_local_max(roi_crop, min_distance=5)\n",
    "plt.imshow(roi_crop, cmap='gray')\n",
    "plt.scatter(coords[:, 1], coords[:, 0], s=10, c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8d224e",
   "metadata": {},
   "source": [
    "Detect local peaks in ROI number 12 using a minimum distance of 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87c6db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85ebb849",
   "metadata": {},
   "source": [
    "Detect local peaks in ROI number 11 using a minimum distance of 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db6da77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd6ae990",
   "metadata": {},
   "source": [
    "*How do I enhance only the neuron to make sure it needs splitting?*\n",
    "\n",
    "**Example** Normalize the cropped ROI and enhance its contrast using adaptive histogram equalization with a clip limit of 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4014c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = labeled_rois == 11\n",
    "roi_crop = proj * roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf77b5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_crop_norm = roi_crop / roi_crop.max()\n",
    "enhanced = equalize_adapthist(roi_crop_norm, clip_limit=0.4)\n",
    "plt.imshow(enhanced, cmap='gray')\n",
    "plt.scatter(coords[:, 1], coords[:, 0], s=10, c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b97360",
   "metadata": {},
   "source": [
    "Normalize the cropped ROI and enhance its contrast using adaptive histogram equalization with a clip limit of 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e138d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d679a80f",
   "metadata": {},
   "source": [
    "Normalize the cropped ROI and enhance its contrast using adaptive histogram equalization with a clip limit of 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06102429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "baa3844d",
   "metadata": {},
   "source": [
    "## Watershed Algorithm For Splitting ROIs\n",
    "\n",
    "The watershed algorithm is a technique that treats the image like a topographic surface, where pixel intensity represents elevation. It \"floods\" the image from marked points (called markers), and boundaries (edges) are determined by the \"watershed lines\" where the flooding from different markers meets.\n",
    "\n",
    "The watershed algorithm uses markers to start the flooding process and a distance map to guide the flow. A distance map is an image where each pixel represents the distance from that pixel to the nearest background pixel. Markers are just coordinates of the local intensity peaks.\n",
    "\n",
    "\n",
    "| **Code**                                  | **Description**                                                                                                                                       |\n",
    "| :---------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `ndi.distance_transform_edt(enhanced)`    | Compute the **Euclidean distance transform** of the **enhanced image**, where each pixel's value is the distance to the nearest background pixel.     |\n",
    "| `watershed(-distance, markers, mask=roi)` | Apply the **watershed segmentation** algorithm to the **negative distance map**, using **markers** to define initial regions and **roi** as the mask. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7fb67d",
   "metadata": {},
   "source": [
    "**Example** Split ROI 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19a04d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = labeled_rois == 11\n",
    "roi_crop = proj * roi\n",
    "roi_crop_norm = roi_crop / roi_crop.max()\n",
    "enhanced = equalize_adapthist(roi_crop_norm, clip_limit=0.1)\n",
    "coords = peak_local_max(enhanced, min_distance=5)\n",
    "markers = np.zeros_like(enhanced, dtype=np.int32)\n",
    "for i, (y, x) in enumerate(coords):\n",
    "    markers[y, x] = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa1c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = ndi.distance_transform_edt(enhanced)\n",
    "labels = watershed(-distance, markers, mask=roi)\n",
    "plt.imshow(labels, cmap=\"nipy_spectral\")\n",
    "plt.scatter(coords[:, 1], coords[:, 0], s=10, c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de2f808",
   "metadata": {},
   "source": [
    "Split ROI 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e01290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8121a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3df7edaa",
   "metadata": {},
   "source": [
    "Split ROI 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e04f604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e34ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
